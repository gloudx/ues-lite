// Package datastore предоставляет расширенный интерфейс для работы с хранилищем данных,
// построенный на основе go-datastore и BadgerDB. Этот пакет реализует высокоуровневые операции
// для работы с ключ-значение хранилищем с поддержкой транзакций, батчинга, TTL и итераторов.
package datastore

import (
	"context"
	"time"

	ds "github.com/ipfs/go-datastore"       // Базовый интерфейс datastore из IPFS экосистемы
	"github.com/ipfs/go-datastore/query"    // Система запросов для datastore
	badger4 "github.com/ipfs/go-ds-badger4" // BadgerDB v4 адаптер для go-datastore
)

// Datastore представляет расширенный интерфейс хранилища данных с дополнительными возможностями.
// Он объединяет в себе все основные функции IPFS datastore и добавляет специализированные методы
// для работы с итераторами, слиянием хранилищ и управлением ключами.
type Datastore interface {
	// Встраивание базового интерфейса datastore, предоставляющего стандартные операции:
	// Get, Put, Delete, Has, GetSize и Query для работы с ключ-значение парами
	ds.Datastore

	// BatchingFeature добавляет поддержку пакетных операций для оптимизации производительности.
	// Позволяет группировать несколько операций записи/удаления в одну атомарную транзакцию
	ds.BatchingFeature

	// TxnFeature предоставляет поддержку транзакций с ACID гарантиями.
	// Обеспечивает атомарность, консистентность, изоляцию и долговечность операций
	ds.TxnFeature

	// GCFeature добавляет возможности сборки мусора для оптимизации использования дискового пространства.
	// Позволяет освобождать неиспользуемые блоки данных и дефрагментировать хранилище
	ds.GCFeature

	// PersistentFeature гарантирует персистентность данных между перезапусками приложения.
	// Обеспечивает сохранение данных на диске и их восстановление после сбоев
	ds.PersistentFeature

	// TTL (Time To Live) добавляет поддержку автоматического истечения срока действия ключей.
	// Позволяет устанавливать временные ограничения на хранение данных
	ds.TTL

	// Iterator создает асинхронный итератор для обхода ключей с заданным префиксом.
	// Метод возвращает два канала: один для данных (KeyValue пары), другой для ошибок.
	//
	// Параметры:
	//   - ctx: контекст для управления временем жизни итератора и отмены операции
	//   - prefix: префикс ключей для фильтрации результатов (пустой префикс означает все ключи)
	//   - keysOnly: если true, возвращает только ключи без значений для экономии памяти
	//
	// Возвращает:
	//   - <-chan KeyValue: канал для получения пар ключ-значение
	//   - <-chan error: канал для получения ошибок во время итерации
	//   - error: ошибка инициализации итератора
	Iterator(ctx context.Context, prefix ds.Key, keysOnly bool) (<-chan KeyValue, <-chan error, error)

	// Merge выполняет слияние текущего хранилища с другим хранилищем данных.
	// Копирует все ключ-значение пары из другого хранилища в текущее с использованием батчинга
	// для оптимизации производительности. Операция атомарная - либо все данные копируются успешно,
	// либо изменения откатываются при ошибке.
	//
	// Параметры:
	//   - ctx: контекст для управления временем жизни операции и возможности отмены
	//   - other: исходное хранилище данных для копирования
	//
	// Возвращает:
	//   - error: ошибка выполнения операции слияния
	Merge(ctx context.Context, other Datastore) error

	// Clear полностью очищает хранилище данных, удаляя все ключ-значение пары.
	// Операция выполняется с использованием батчинга для оптимизации производительности.
	// Внимание: эта операция необратима и удаляет все данные из хранилища.
	//
	// Параметры:
	//   - ctx: контекст для управления временем жизни операции и возможности отмены
	//
	// Возвращает:
	//   - error: ошибка выполнения операции очистки
	Clear(ctx context.Context) error

	// Keys создает асинхронный итератор для получения всех ключей с заданным префиксом.
	// В отличие от Iterator, возвращает только ключи без значений, что экономит память
	// при работе с большими объемами данных.
	//
	// Параметры:
	//   - ctx: контекст для управления временем жизни итератора и отмены операции
	//   - prefix: префикс ключей для фильтрации результатов
	//
	// Возвращает:
	//   - <-chan ds.Key: канал для получения ключей
	//   - <-chan error: канал для получения ошибок во время итерации
	//   - error: ошибка инициализации итератора ключей
	Keys(ctx context.Context, prefix ds.Key) (<-chan ds.Key, <-chan error, error)
}

// KeyValue представляет простую структуру для хранения пары ключ-значение.
// Используется в итераторах для передачи данных через каналы и обеспечивает
// типобезопасное представление элементов хранилища данных.
type KeyValue struct {
	Key   ds.Key // Ключ в формате datastore (иерархическая строка разделенная слешами)
	Value []byte // Значение в виде массива байт (сериализованные данные)
}

// Compile-time проверки соответствия интерфейсам для обеспечения корректной реализации.
// Эти объявления гарантируют, что структура datastorage корректно реализует все необходимые интерфейсы
// из экосистемы go-datastore. Если какой-то метод не реализован, компилятор выдаст ошибку.
var _ ds.Datastore = (*datastorage)(nil)           // Базовый интерфейс для операций с ключ-значение парами
var _ ds.PersistentDatastore = (*datastorage)(nil) // Интерфейс для персистентного хранилища данных
var _ ds.TxnDatastore = (*datastorage)(nil)        // Интерфейс для поддержки транзакций
var _ ds.TTLDatastore = (*datastorage)(nil)        // Интерфейс для поддержки TTL (время жизни ключей)
var _ ds.GCDatastore = (*datastorage)(nil)         // Интерфейс для поддержки сборки мусора
var _ ds.Batching = (*datastorage)(nil)            // Интерфейс для поддержки пакетных операций

// datastorage представляет конкретную реализацию расширенного интерфейса Datastore.
// Структура встраивает BadgerDB datastore и добавляет дополнительные методы для работы
// с итераторами, слиянием и управлением ключами. BadgerDB обеспечивает высокую производительность
// и надежность хранения данных на основе LSM-tree архитектуры.
type datastorage struct {
	*badger4.Datastore // Встроенное хранилище данных на основе BadgerDB v4
}

// NewDatastorage создает новый экземпляр расширенного хранилища данных на основе BadgerDB.
// Функция инициализирует BadgerDB с заданными параметрами и оборачивает его в структуру datastorage
// для предоставления дополнительных методов работы с данными.
//
// BadgerDB - это встраиваемая, персистентная, быстрая база данных ключ-значение, написанная на Go.
// Она использует LSM-tree (Log-Structured Merge-tree) архитектуру для обеспечения высокой производительности
// записи и чтения данных. База данных поддерживает ACID транзакции, TTL, сжатие данных и эффективную сборку мусора.
//
// Параметры:
//   - path: путь к директории для хранения файлов базы данных BadgerDB.
//     Директория будет создана автоматически, если не существует.
//   - opts: опции конфигурации BadgerDB, включающие настройки производительности,
//     размеры буферов, параметры компактификации и другие настройки базы данных.
//     Может быть nil для использования настроек по умолчанию.
//
// Возвращает:
//   - Datastore: интерфейс расширенного хранилища данных с дополнительными методами
//   - error: ошибка инициализации BadgerDB или создания экземпляра хранилища
//
// Возможные ошибки:
//   - Ошибки файловой системы при создании директории или открытии файлов
//   - Ошибки конфигурации BadgerDB при некорректных параметрах
//   - Ошибки блокировки при попытке открыть уже используемую базу данных
func NewDatastorage(path string, opts *badger4.Options) (Datastore, error) {
	// Создаем экземпляр BadgerDB datastore с заданными параметрами
	badgerDS, err := badger4.NewDatastore(path, opts)
	if err != nil {
		return nil, err
	}

	// Оборачиваем BadgerDB datastore в нашу расширенную структуру
	return &datastorage{Datastore: badgerDS}, nil
}

// Iterator создает асинхронный итератор для обхода ключ-значение пар с заданным префиксом.
// Метод реализует неблокирующий паттерн итерации с использованием каналов для обеспечения
// конкурентной безопасности и возможности отмены операции через контекст.
//
// Алгоритм работы:
// 1. Создается запрос к базовому datastore с заданным префиксом и флагом keysOnly
// 2. Запускается горутина, которая читает результаты запроса и отправляет их в каналы
// 3. Горутина обрабатывает сигналы отмены через контекст и корректно закрывает ресурсы
// 4. При ошибках или завершении данных горутина сигнализирует об окончании работы
//
// Особенности реализации:
// - Неблокирующий доступ к данным через каналы
// - Автоматическое управление ресурсами с помощью defer
// - Обработка контекста отмены для прерывания длительных операций
// - Безопасное закрытие каналов для предотвращения утечек горутин
//
// Параметры:
//   - ctx: контекст для управления временем жизни итератора и отмены операции.
//     При отмене контекста итератор завершает работу и освобождает ресурсы.
//   - prefix: префикс ключей для фильтрации результатов. Поддерживает иерархическую структуру
//     с разделителем "/". Пустой префикс означает итерацию по всем ключам.
//   - keysOnly: если true, возвращает только ключи без значений, что экономит память
//     и ускоряет работу при обработке больших объемов данных.
//
// Возвращает:
//   - <-chan KeyValue: канал только для чтения, через который передаются пары ключ-значение.
//     Канал закрывается при завершении итерации или ошибке.
//   - <-chan error: канал только для чтения для передачи ошибок во время итерации.
//     Канал закрывается вместе с каналом данных.
//   - error: ошибка инициализации итератора, возникающая до запуска горутины
//
// Пример использования:
//
//	data, errs, err := ds.Iterator(ctx, ds.NewKey("/users"), false)
//	if err != nil { return err }
//	for {
//	  select {
//	  case kv, ok := <-data:
//	    if !ok { return nil } // итерация завершена
//	    // обработка kv.Key и kv.Value
//	  case err := <-errs:
//	    if err != nil { return err }
//	  case <-ctx.Done():
//	    return ctx.Err()
//	  }
//	}
func (s *datastorage) Iterator(ctx context.Context, prefix ds.Key, keysOnly bool) (<-chan KeyValue, <-chan error, error) {
	// Создаем запрос с заданным префиксом и флагом для получения только ключей
	q := query.Query{
		Prefix:   prefix.String(), // Преобразуем ключ в строковое представление для запроса
		KeysOnly: keysOnly,        // Флаг определяет, нужны ли значения или только ключи
	}

	// Выполняем запрос к базовому datastore
	result, err := s.Datastore.Query(ctx, q)
	if err != nil {
		return nil, nil, err
	}

	// Создаем каналы для передачи данных и ошибок
	out := make(chan KeyValue)  // Канал для передачи пар ключ-значение
	errc := make(chan error, 1) // Буферизованный канал для ошибок (предотвращает блокировку)

	// Запускаем горутину для асинхронной обработки результатов запроса
	go func() {
		// Гарантируем закрытие каналов и освобождение ресурсов при завершении функции
		defer close(out)     // Закрываем канал данных
		defer close(errc)    // Закрываем канал ошибок
		defer result.Close() // Закрываем результат запроса и освобождаем ресурсы datastore

		// Основной цикл обработки результатов
		for {
			select {
			// Обработка сигнала отмены контекста
			case <-ctx.Done():
				errc <- ctx.Err() // Отправляем ошибку отмены в канал ошибок
				return

			// Получение следующего результата из запроса
			case res, ok := <-result.Next():
				// Проверяем, не закрылся ли канал результатов (итерация завершена)
				if !ok {
					return // Выходим из цикла, каналы закроются через defer
				}

				// Проверяем наличие ошибки в результате
				if res.Error != nil {
					errc <- res.Error // Отправляем ошибку в канал ошибок
					return
				}

				// Отправляем успешный результат в канал данных
				out <- KeyValue{
					Key:   ds.NewKey(res.Key), // Создаем ключ из строкового представления
					Value: res.Value,          // Значение уже в нужном формате ([]byte)
				}
			}
		}
	}()

	return out, errc, nil
}

// Merge выполняет слияние текущего хранилища данных с другим хранилищем.
// Метод копирует все ключ-значение пары из исходного хранилища в текущее с использованием
// пакетных операций для оптимизации производительности и обеспечения атомарности.
//
// Алгоритм работы:
// 1. Создается пакетная операция (batch) для группировки множественных записей
// 2. Создается итератор для обхода всех элементов исходного хранилища
// 3. Каждая пара ключ-значение добавляется в пакет
// 4. В конце пакет коммитится атомарно - либо все изменения применяются, либо откатываются
//
// Особенности реализации:
// - Использование корневого префикса "/" для итерации по всем ключам
// - Асинхронная обработка с поддержкой отмены через контекст
// - Правильная обработка закрытия каналов ошибок во время итерации
// - Атомарность операции благодаря пакетному режиму
//
// Производительность:
// - Пакетные операции значительно быстрее одиночных записей
// - BadgerDB оптимизирует пакетные записи на уровне LSM-tree
// - Использование итераторов минимизирует потребление памяти
//
// Параметры:
//   - ctx: контекст для управления временем жизни операции и возможности отмены.
//     При отмене контекста операция прерывается и изменения откатываются.
//   - other: исходное хранилище данных, из которого копируются все ключ-значение пары.
//     Хранилище должно реализовывать интерфейс Datastore с методом Iterator.
//
// Возвращает:
//   - error: ошибка выполнения операции слияния
//
// Возможные ошибки:
//   - Ошибки создания пакетной операции
//   - Ошибки инициализации итератора исходного хранилища
//   - Ошибки добавления записей в пакет
//   - Ошибки коммита пакетной операции
//   - Ошибки отмены операции через контекст
//
// Пример использования:
//
//	sourceDS := // создание исходного хранилища
//	targetDS := // создание целевого хранилища
//	err := targetDS.Merge(ctx, sourceDS)
//	if err != nil { log.Fatal("Ошибка слияния:", err) }
func (s *datastorage) Merge(ctx context.Context, other Datastore) error {
	// Создаем пакетную операцию для атомарного выполнения множественных записей
	batch, err := s.Batch(ctx)
	if err != nil {
		return err
	}

	// Создаем итератор для обхода всех элементов исходного хранилища
	// Используем корневой префикс "/" для получения всех ключей
	// Флаг false означает, что нужны и ключи, и значения
	it, errc, err := other.Iterator(ctx, ds.NewKey("/"), false)
	if err != nil {
		return err
	}

	// Основной цикл обработки элементов из исходного хранилища
	for {
		select {
		// Обработка сигнала отмены контекста
		case <-ctx.Done():
			return ctx.Err() // Возвращаем ошибку отмены

		// Обработка ошибок из канала ошибок итератора
		case e, ok := <-errc:
			if ok && e != nil {
				return e // Возвращаем ошибку итерации
			}
			// Канал ошибок закрылся без ошибки - продолжаем дренировать канал данных
			// Устанавливаем errc в nil, чтобы больше не обрабатывать этот case
			errc = nil

		// Обработка пар ключ-значение из канала данных итератора
		case kv, ok := <-it:
			if !ok {
				// Канал данных закрылся - все элементы обработаны
				// Коммитим пакетную операцию для атомарного применения всех изменений
				return batch.Commit(ctx)
			}

			// Добавляем текущую пару ключ-значение в пакетную операцию
			if err := batch.Put(ctx, kv.Key, kv.Value); err != nil {
				return err // Возвращаем ошибку добавления в пакет
			}
		}
	}
}

// Clear полностью очищает хранилище данных, удаляя все ключ-значение пары.
// Метод выполняет безопасную операцию массового удаления с использованием пакетных операций
// для обеспечения атомарности и оптимизации производительности.
//
// Алгоритм работы:
// 1. Создается запрос для получения всех ключей в хранилище (без значений для экономии памяти)
// 2. Создается пакетная операция для группировки операций удаления
// 3. Все ключи добавляются в пакет как операции удаления
// 4. Пакет коммитится атомарно - либо все ключи удаляются, либо операция откатывается
//
// Особенности реализации:
// - Использование KeysOnly=true для минимизации использования памяти
// - Автоматическое управление ресурсами с помощью defer
// - Поддержка отмены операции через контекст
// - Атомарность операции благодаря пакетному режиму
//
// Производительность:
// - Пакетные удаления значительно быстрее одиночных операций
// - Получение только ключей экономит память и сетевой трафик
// - BadgerDB оптимизирует пакетные операции на уровне хранилища
//
// Безопасность:
// - Операция необратима - все данные будут потеряны
// - Атомарность гарантирует, что либо все данные удалены, либо остаются нетронутыми
// - Контекст позволяет отменить операцию до её завершения
//
// Параметры:
//   - ctx: контекст для управления временем жизни операции и возможности отмены.
//     При отмене контекста операция прерывается до коммита изменений.
//
// Возвращает:
//   - error: ошибка выполнения операции очистки
//
// Возможные ошибки:
//   - Ошибки создания запроса для получения ключей
//   - Ошибки создания пакетной операции
//   - Ошибки добавления операций удаления в пакет
//   - Ошибки коммита пакетной операции
//   - Ошибки отмены операции через контекст
//
// Предупреждение:
//
//	Эта операция НЕОБРАТИМА! Все данные в хранилище будут безвозвратно удалены.
//	Убедитесь, что у вас есть резервные копии важных данных перед вызовом этого метода.
//
// Пример использования:
//
//	err := ds.Clear(ctx)
//	if err != nil { log.Fatal("Ошибка очистки хранилища:", err) }
//	log.Println("Хранилище успешно очищено")
func (s *datastorage) Clear(ctx context.Context) error {
	// Создаем запрос для получения всех ключей в хранилище
	// KeysOnly=true означает, что нам нужны только ключи без значений
	// Это экономит память и ускоряет операцию при работе с большими объемами данных
	q, err := s.Query(ctx, query.Query{
		KeysOnly: true,
	})
	if err != nil {
		return err
	}
	// Гарантируем закрытие запроса для освобождения ресурсов
	defer q.Close()

	// Создаем пакетную операцию для атомарного выполнения множественных удалений
	b, err := s.Batch(ctx)
	if err != nil {
		return err
	}

	// Основной цикл обработки ключей для удаления
	for {
		select {
		// Обработка сигнала отмены контекста
		case <-ctx.Done():
			return ctx.Err() // Возвращаем ошибку отмены

		// Получение следующего ключа из результатов запроса
		case res, ok := <-q.Next():
			if !ok {
				// Канал результатов закрылся - все ключи обработаны
				// Коммитим пакетную операцию для атомарного удаления всех ключей
				return b.Commit(ctx)
			}

			// Проверяем наличие ошибки в результате
			if res.Error != nil {
				return res.Error // Возвращаем ошибку получения ключа
			}

			// Добавляем операцию удаления текущего ключа в пакет
			if err := b.Delete(ctx, ds.NewKey(res.Key)); err != nil {
				return err // Возвращаем ошибку добавления операции удаления
			}
		}
	}
}

// Keys создает асинхронный итератор для получения всех ключей с заданным префиксом.
// Метод предоставляет эффективный способ получения только ключей без значений,
// что существенно экономит память и ускоряет работу при анализе структуры данных.
//
// Алгоритм работы:
// 1. Создается запрос к базовому datastore с флагом KeysOnly=true
// 2. Запускается горутина для асинхронной обработки результатов
// 3. Результаты фильтруются по префиксу и передаются через канал ключей
// 4. Ошибки обрабатываются отдельно через канал ошибок
//
// Отличия от Iterator:
// - Возвращает только ключи (ds.Key) вместо пар KeyValue
// - Потребляет меньше памяти из-за отсутствия значений
// - Быстрее работает при анализе структуры хранилища
// - Оптимален для операций подсчета, валидации ключей, построения индексов
//
// Применение:
// - Анализ структуры данных в хранилище
// - Подсчет количества записей с определенным префиксом
// - Валидация существования ключей
// - Построение индексов и каталогов
// - Синхронизация метаданных между хранилищами
//
// Параметры:
//   - ctx: контекст для управления временем жизни итератора и отмены операции.
//     При отмене контекста итератор корректно завершает работу и освобождает ресурсы.
//   - prefix: префикс ключей для фильтрации результатов. Поддерживает иерархическую структуру
//     с разделителем "/". Например, "/users" вернет все ключи пользователей.
//     Пустой префикс ds.NewKey("") означает получение всех ключей в хранилище.
//
// Возвращает:
//   - <-chan ds.Key: канал только для чтения, через который передаются ключи.
//     Канал автоматически закрывается при завершении итерации.
//   - <-chan error: канал только для чтения для передачи ошибок во время итерации.
//     Канал закрывается одновременно с каналом ключей.
//   - error: ошибка инициализации итератора, возникающая до запуска горутины
//
// Возможные ошибки:
//   - Ошибки создания запроса к datastore
//   - Ошибки доступа к хранилищу данных
//   - Ошибки чтения ключей из результатов запроса
//   - Ошибки отмены операции через контекст
//
// Пример использования:
//
//	keys, errs, err := ds.Keys(ctx, ds.NewKey("/users"))
//	if err != nil { return err }
//	count := 0
//	for {
//	  select {
//	  case key, ok := <-keys:
//	    if !ok {
//	      log.Printf("Найдено %d ключей пользователей", count)
//	      return nil
//	    }
//	    count++
//	    log.Printf("Ключ: %s", key.String())
//	  case err := <-errs:
//	    if err != nil { return err }
//	  case <-ctx.Done():
//	    return ctx.Err()
//	  }
//	}
func (s *datastorage) Keys(ctx context.Context, prefix ds.Key) (<-chan ds.Key, <-chan error, error) {
	// Создаем запрос с заданным префиксом и флагом для получения только ключей
	q := query.Query{
		Prefix:   prefix.String(), // Преобразуем ключ в строковое представление для фильтрации
		KeysOnly: true,            // Важно: получаем только ключи для экономии памяти и производительности
	}

	// Выполняем запрос к базовому datastore
	result, err := s.Datastore.Query(ctx, q)
	if err != nil {
		return nil, nil, err
	}

	// Создаем каналы для передачи ключей и ошибок
	out := make(chan ds.Key)    // Канал для передачи ключей
	errc := make(chan error, 1) // Буферизованный канал для ошибок (предотвращает блокировку)

	// Запускаем горутину для асинхронной обработки результатов запроса
	go func() {
		// Гарантируем закрытие каналов и освобождение ресурсов при завершении функции
		defer close(out)     // Закрываем канал ключей
		defer close(errc)    // Закрываем канал ошибок
		defer result.Close() // Закрываем результат запроса и освобождаем ресурсы datastore

		// Основной цикл обработки результатов
		for {
			select {
			// Обработка сигнала отмены контекста
			case <-ctx.Done():
				errc <- ctx.Err() // Отправляем ошибку отмены в канал ошибок
				return

			// Получение следующего результата из запроса
			case res, ok := <-result.Next():
				// Проверяем, не закрылся ли канал результатов (итерация завершена)
				if !ok {
					return // Выходим из цикла, каналы закроются через defer
				}

				// Проверяем наличие ошибки в результате
				if res.Error != nil {
					errc <- res.Error // Отправляем ошибку в канал ошибок
					return
				}

				// Отправляем успешный результат в канал ключей
				out <- ds.NewKey(res.Key) // Создаем ключ из строкового представления
			}
		}
	}()

	return out, errc, nil
}

// PutWithTTL сохраняет ключ-значение пару с автоматическим истечением срока действия.
// Метод предоставляет возможность создания временных записей, которые автоматически
// удаляются из хранилища по истечении заданного времени жизни (TTL - Time To Live).
//
// Принцип работы TTL:
// - BadgerDB использует внутренний механизм отслеживания времени истечения
// - Записи с истекшим TTL становятся недоступными для чтения
// - Физическое удаление происходит во время сборки мусора (garbage collection)
// - TTL проверяется при каждом обращении к ключу
//
// Особенности реализации:
// - При ttl <= 0 выполняется обычная операция Put без TTL
// - Время отсчитывается от момента записи в хранилище
// - TTL сохраняется даже при перезапуске приложения (персистентность)
// - Можно обновить TTL существующего ключа с помощью SetTTL
//
// Применение:
// - Кэширование данных с автоматическим истечением
// - Временные сессии и токены аутентификации
// - Данные для отладки и логирования
// - Временные блокировки и семафоры
// - Уведомления и сообщения с ограниченным сроком действия
//
// Производительность:
// - TTL записи работают с той же скоростью, что и обычные
// - Проверка TTL добавляет минимальные накладные расходы при чтении
// - Сборка мусора происходит в фоне и не блокирует операции
//
// Параметры:
//   - ctx: контекст для управления временем жизни операции и возможности отмены
//   - key: ключ для сохранения данных в иерархическом формате datastore
//   - value: значение в виде массива байт для сохранения
//   - ttl: время жизни записи. При ttl <= 0 TTL не устанавливается и запись
//     сохраняется как обычная (без автоматического удаления)
//
// Возвращает:
//   - error: ошибка выполнения операции сохранения
//
// Возможные ошибки:
//   - Ошибки записи в хранилище данных
//   - Ошибки установки TTL в BadgerDB
//   - Ошибки отмены операции через контекст
//   - Ошибки доступа к файловой системе
//
// Пример использования:
//
//	// Сохранение сессии на 1 час
//	sessionKey := ds.NewKey("/sessions/user123")
//	sessionData := []byte(`{"user_id": 123, "created": "2024-01-01"}`)
//	err := ds.PutWithTTL(ctx, sessionKey, sessionData, time.Hour)
//	if err != nil { log.Fatal("Ошибка сохранения сессии:", err) }
//
//	// Сохранение без TTL (обычная запись)
//	permanentKey := ds.NewKey("/users/123")
//	userData := []byte(`{"name": "John", "email": "john@example.com"}`)
//	err = ds.PutWithTTL(ctx, permanentKey, userData, 0)
func (s *datastorage) PutWithTTL(ctx context.Context, key ds.Key, value []byte, ttl time.Duration) error {
	// Проверяем значение TTL
	if ttl <= 0 {
		// При неположительном TTL выполняем обычную операцию Put
		// Это означает, что запись будет храниться бессрочно
		return s.Datastore.Put(ctx, key, value)
	}

	// Выполняем запись с установкой TTL через BadgerDB
	return s.Datastore.PutWithTTL(ctx, key, value, ttl)
}

// SetTTL обновляет время жизни (TTL) для существующего ключа в хранилище.
// Метод позволяет изменить срок действия уже сохраненной записи без изменения её значения.
// Это полезно для продления срока действия активных сессий, обновления кэша или
// изменения политики хранения данных.
//
// Принцип работы:
// - Обновляет метаданные времени истечения для указанного ключа
// - Новый TTL отсчитывается от момента вызова SetTTL
// - Если ключ не существует, операция может завершиться ошибкой (зависит от реализации BadgerDB)
// - Изменения TTL персистентны и сохраняются при перезапуске
//
// Особенности реализации:
// - При ttl <= 0 TTL снимается и запись становится постоянной
// - Операция атомарная - TTL либо обновляется полностью, либо остается прежним
// - Не влияет на значение ключа, изменяет только метаданные времени
// - Работает быстро, так как не требует чтения/записи основных данных
//
// Применение:
// - Продление активных сессий пользователей
// - Обновление времени жизни кэшированных данных
// - Реализация алгоритмов истечения с переменным временем
// - Управление временными блокировками и семафорами
// - Конвертирование временных записей в постоянные
//
// Управление временем жизни:
// - ttl > 0: устанавливает новое время жизни от текущего момента
// - ttl = 0: снимает TTL, делая запись постоянной
// - ttl < 0: также снимает TTL (трактуется как 0)
//
// Параметры:
//   - ctx: контекст для управления временем жизни операции и возможности отмены
//   - key: ключ существующей записи для обновления TTL
//   - ttl: новое время жизни записи. При ttl <= 0 TTL снимается полностью,
//     и запись становится постоянной (не удаляется автоматически)
//
// Возвращает:
//   - error: ошибка выполнения операции обновления TTL
//
// Возможные ошибки:
//   - Ошибки доступа к метаданным ключа в BadgerDB
//   - Ошибки обновления TTL в хранилище
//   - Ошибки отмены операции через контекст
//   - Ошибки при работе с несуществующими ключами (зависит от реализации)
//
// Пример использования:
//
//	// Продление сессии пользователя на 2 часа
//	sessionKey := ds.NewKey("/sessions/user123")
//	err := ds.SetTTL(ctx, sessionKey, 2*time.Hour)
//	if err != nil { log.Printf("Ошибка продления сессии: %v", err) }
//
//	// Снятие TTL - делаем запись постоянной
//	cacheKey := ds.NewKey("/cache/important-data")
//	err = ds.SetTTL(ctx, cacheKey, 0)
//	if err != nil { log.Printf("Ошибка снятия TTL: %v", err) }
//
//	// Установка короткого TTL для отладочных данных
//	debugKey := ds.NewKey("/debug/temp-logs")
//	err = ds.SetTTL(ctx, debugKey, 5*time.Minute)
func (s *datastorage) SetTTL(ctx context.Context, key ds.Key, ttl time.Duration) error {
	if ttl <= 0 {
		// BadgerDB трактует неположительный TTL как команду снятия таймера
		// Устанавливаем 0 для явного снятия TTL
		return s.Datastore.SetTTL(ctx, key, 0)
	}

	// Устанавливаем новый TTL для ключа
	return s.Datastore.SetTTL(ctx, key, ttl)
}

// GetExpiration возвращает точное время истечения TTL для указанного ключа.
// Метод предоставляет возможность проверить, когда именно запись будет автоматически
// удалена из хранилища, что полезно для мониторинга, отладки и планирования операций.
//
// Принцип работы:
// - Извлекает метаданные времени истечения из BadgerDB
// - Возвращает абсолютное время в UTC, когда ключ станет недоступным
// - Для ключей без TTL возвращает нулевое время (time.Time{})
// - Время рассчитывается на основе момента установки TTL
//
// Особенности реализации:
// - Возвращает время в формате time.Time для удобной работы с датами
// - Нулевое время (time.IsZero() == true) означает отсутствие TTL
// - Время всегда в UTC для избежания проблем с часовыми поясами
// - Быстрая операция - читает только метаданные, не основные данные
//
// Применение:
// - Мониторинг времени жизни кэшированных данных
// - Планирование обновления записей перед истечением
// - Отладка и диагностика проблем с TTL
// - Реализация уведомлений о скором истечении
// - Синхронизация TTL между разными компонентами системы
//
// Интерпретация результата:
// - time.Time{} (IsZero() == true): TTL не установлен, запись постоянная
// - Время в прошлом: ключ уже истек и должен быть недоступен
// - Время в будущем: ключ действителен до указанного момента
// - Время близко к текущему: ключ скоро истечет
//
// Параметры:
//   - ctx: контекст для управления временем жизни операции и возможности отмены
//   - key: ключ для проверки времени истечения TTL
//
// Возвращает:
//   - time.Time: абсолютное время истечения TTL в формате UTC.
//     Если TTL не установлен, возвращается нулевое время (time.Time{}).
//   - error: ошибка получения информации о TTL
//
// Возможные ошибки:
//   - Ошибки доступа к метаданным ключа в BadgerDB
//   - Ошибки чтения TTL информации из хранилища
//   - Ошибки отмены операции через контекст
//   - Ошибки при работе с несуществующими ключами
//
// Пример использования:
//
//	sessionKey := ds.NewKey("/sessions/user123")
//
//	// Проверка времени истечения сессии
//	expiration, err := ds.GetExpiration(ctx, sessionKey)
//	if err != nil {
//	  log.Printf("Ошибка получения TTL: %v", err)
//	  return
//	}
//
//	if expiration.IsZero() {
//	  log.Println("Сессия не имеет TTL (постоянная)")
//	} else if time.Now().After(expiration) {
//	  log.Println("Сессия уже истекла")
//	} else {
//	  remaining := time.Until(expiration)
//	  log.Printf("Сессия истечет через: %v", remaining)
//
//	  // Продление сессии, если осталось меньше 10 минут
//	  if remaining < 10*time.Minute {
//	    err := ds.SetTTL(ctx, sessionKey, time.Hour)
//	    if err != nil {
//	      log.Printf("Ошибка продления сессии: %v", err)
//	    }
//	  }
//	}
func (s *datastorage) GetExpiration(ctx context.Context, key ds.Key) (time.Time, error) {
	// Получаем время истечения TTL из базового BadgerDB datastore
	return s.Datastore.GetExpiration(ctx, key)
}

// Close корректно закрывает хранилище данных и освобождает все связанные ресурсы.
// Метод обеспечивает безопасное завершение работы с BadgerDB, включая закрытие файлов,
// освобождение памяти и завершение фоновых горутин.
//
// Принцип работы:
// - Завершает все активные транзакции и операции записи
// - Сбрасывает буферы данных на диск (flush)
// - Закрывает файловые дескрипторы BadgerDB
// - Освобождает память, занятую кэшами и буферами
// - Завершает фоновые горутины сборки мусора и компактификации
//
// Важность корректного закрытия:
// - Предотвращает потерю данных при аварийном завершении
// - Освобождает блокировки файлов для повторного открытия
// - Завершает фоновые процессы BadgerDB
// - Предотвращает утечки памяти и файловых дескрипторов
// - Обеспечивает консистентность данных на диске
//
// Последовательность закрытия:
// 1. Завершение новых операций (новые операции будут отклонены)
// 2. Ожидание завершения активных транзакций
// 3. Принудительная запись буферов на диск
// 4. Закрытие файлов базы данных
// 5. Освобождение ресурсов памяти
//
// Безопасность:
// - Метод безопасен для многократного вызова
// - После закрытия все операции с хранилищем будут возвращать ошибки
// - Блокирует до полного завершения процесса закрытия
// - Не требует контекста, так как это критическая операция
//
// Возвращает:
//   - error: ошибка закрытия хранилища данных
//
// Возможные ошибки:
//   - Ошибки записи буферов на диск
//   - Ошибки закрытия файлов базы данных
//   - Ошибки завершения фоновых процессов
//   - Ошибки освобождения системных ресурсов
//
// Пример использования:
//
//	ds, err := NewDatastorage("/path/to/db", nil)
//	if err != nil { log.Fatal(err) }
//
//	// Использование хранилища...
//
//	// Корректное закрытие при завершении программы
//	defer func() {
//	  if err := ds.Close(); err != nil {
//	    log.Printf("Ошибка закрытия хранилища: %v", err)
//	  }
//	}()
//
// Рекомендации:
//   - Всегда используйте defer для гарантированного закрытия
//   - Проверяйте ошибки закрытия для диагностики проблем
//   - Не используйте хранилище после вызова Close()
//   - В критических приложениях реализуйте graceful shutdown
func (s *datastorage) Close() error {
	// Закрываем базовое BadgerDB хранилище данных
	// BadgerDB реализует интерфейс io.Closer для корректного управления ресурсами
	return s.Datastore.Close()
}

package headstorage

import (
	"context"
	"encoding/json"
	"fmt"
	"sync"

	"github.com/ipfs/go-cid"
	ds "github.com/ipfs/go-datastore"
)

// HeadStorage управляет персистентным хранением состояния HEAD репозитория.
// Интерфейс обеспечивает абстракцию над различными механизмами хранения (datastore, файловая система).
// Основная цель - автоматическое сохранение и восстановление состояния между перезапусками приложения,
// а также предоставление механизма подписки на изменения для репликации и синхронизации.
//
// Реализации должны обеспечивать:
// - Атомарность операций записи
// - Консистентность данных при concurrent доступе
// - Уведомления watchers об изменениях состояния
// - Корректную очистку ресурсов при закрытии
type HeadStorage interface {
	// LoadHead загружает последнее состояние HEAD из persistent storage.
	//
	// Параметры:
	//   ctx - контекст для отмены операции и передачи метаданных
	//   repoID - уникальный идентификатор репозитория
	//
	// Возвращает:
	//   RepositoryState - структуру с актуальным состоянием репозитория
	//   error - ошибку, если не удалось загрузить состояние
	//
	// Поведение:
	//   - Если репозиторий еще не инициализирован, возвращает состояние по умолчанию
	//   - При отсутствии данных (новый репозиторий) не считается ошибкой
	//   - Должен быть потокобезопасным для concurrent вызовов
	LoadHead(ctx context.Context, repoID string) (RepositoryState, error)

	// SaveHead сохраняет текущее состояние HEAD в persistent storage.
	//
	// Параметры:
	//   ctx - контекст для отмены операции и передачи метаданных
	//   repoID - уникальный идентификатор репозитория
	//   state - новое состояние репозитория для сохранения
	//
	// Возвращает:
	//   error - ошибку, если не удалось сохранить состояние
	//
	// Поведение:
	//   - Операция должна быть атомарной (либо полностью успешной, либо откатываться)
	//   - После успешного сохранения уведомляет всех watchers об изменении
	//   - Должен быть потокобезопасным для concurrent вызовов
	//   - Сериализует состояние в формат, подходящий для storage backend
	SaveHead(ctx context.Context, repoID string, state RepositoryState) error

	// WatchHead создает канал для подписки на изменения состояния HEAD репозитория.
	// Используется для реализации репликации, синхронизации и real-time уведомлений.
	//
	// Параметры:
	//   ctx - контекст, при отмене которого подписка автоматически закрывается
	//   repoID - уникальный идентификатор репозитория для отслеживания
	//
	// Возвращает:
	//   <-chan RepositoryState - только для чтения канал с уведомлениями об изменениях
	//   error - ошибку, если не удалось создать подписку
	//
	// Поведение:
	//   - Канал буферизованный для предотвращения блокировки при медленных consumer'ах
	//   - При отмене контекста канал автоматически закрывается
	//   - Не отправляет текущее состояние при подписке, только изменения
	//   - При переполнении буфера пропускает уведомления (non-blocking)
	WatchHead(ctx context.Context, repoID string) (<-chan RepositoryState, error)

	// Close корректно закрывает storage и освобождает все связанные ресурсы.
	//
	// Возвращает:
	//   error - ошибку, если не удалось корректно закрыть storage
	//
	// Поведение:
	//   - Закрывает все активные watchers и их каналы
	//   - Освобождает внутренние ресурсы (подключения, файлы, память)
	//   - После вызова Close все остальные методы могут возвращать ошибки
	//   - Должен быть idempotent (безопасен для повторного вызова)
	Close() error
}

// RepositoryState представляет полный снимок состояния репозитория в определенный момент времени.
// Структура содержит всю необходимую информацию для восстановления состояния репозитория
// после перезапуска приложения или для репликации на другие узлы.
//
// Все поля являются обязательными для корректной работы, кроме случаев инициализации нового репозитория.
// Структура сериализуется в JSON для хранения в различных storage backend'ах.
//
// Версионирование:
//
//	Version поле используется для миграций формата при изменении структуры
//	Текущая версия: 1
type RepositoryState struct {
	// Head содержит CID текущего HEAD коммита репозитория.
	// Это основная точка входа для навигации по истории коммитов.
	// При инициализации нового репозитория может быть cid.Undef.
	Head cid.Cid `json:"head"`

	// Prev содержит CID предыдущего коммита в цепочке.
	// Используется для быстрого построения истории и валидации целостности.
	// Для первого коммита в репозитории будет cid.Undef.
	Prev cid.Cid `json:"prev"`

	// RootIndex содержит CID корневого индекса для текущего состояния.
	// Кэшируется для улучшения производительности доступа к данным.
	// Позволяет избежать пересчета индекса при каждом обращении к данным.
	RootIndex cid.Cid `json:"root"`

	// Version указывает версию формата структуры RepositoryState.
	// Используется для обратной совместимости и миграций при изменении схемы.
	// Текущая версия: 1
	Version int `json:"version"`

	// RepoID содержит уникальный идентификатор репозитория.
	// Позволяет различать состояния разных репозиториев в shared storage.
	// Должен быть постоянным в течение всей жизни репозитория.
	RepoID string `json:"repo_id"`
}

// datastoreHeadStorage реализует интерфейс HeadStorage через IPFS datastore.
// Предоставляет надежное, распределенное хранение состояния репозитория
// с поддержкой concurrent доступа и уведомлений об изменениях.
//
// Архитектура:
//   - Использует иерархические ключи для организации данных
//   - Поддерживает множественные watchers для real-time уведомлений
//   - Обеспечивает потокобезопасность через RWMutex
//   - Автоматически управляет жизненным циклом watchers
//
// Формат ключей: /repository/{repoID}/head
// Формат данных: JSON сериализация RepositoryState
type datastoreHeadStorage struct {
	// ds - основное хранилище данных, реализующее интерфейс datastore
	// Обеспечивает персистентность и может быть любой совместимой реализацией
	// (файловой, in-memory, сетевой и т.д.)
	ds ds.Datastore

	// watchers содержит карту активных подписчиков для каждого репозитория
	// Ключ: repoID, Значение: слайс каналов для уведомлений
	// Используется для реализации pub/sub механизма
	watchers map[string][]chan RepositoryState

	// mu обеспечивает потокобезопасный доступ к watchers map
	// RWMutex позволяет concurrent чтение при exclusive записи
	mu sync.RWMutex
}

// NewDatastoreHeadStorage создает новый экземпляр HeadStorage на основе datastore.
// Конструктор инициализирует все внутренние структуры данных и возвращает
// готовый к использованию storage.
//
// Параметры:
//
//	store - реализация datastore для персистентного хранения
//	        Может быть любой совместимой реализацией (file, memory, network)
//
// Возвращает:
//
//	HeadStorage - готовый к использованию storage с инициализированными структурами
//
// Особенности:
//   - Не выполняет никаких I/O операций при создании
//   - Инициализирует пустую карту watchers
//   - Безопасен для concurrent использования сразу после создания
//   - Не проверяет доступность или корректность переданного store
func NewHeadStorage(store ds.Datastore) HeadStorage {
	return &datastoreHeadStorage{
		ds:       store,
		watchers: make(map[string][]chan RepositoryState),
	}
}

// LoadHead загружает последнее сохраненное состояние репозитория из datastore.
// Метод выполняет десериализацию JSON данных в структуру RepositoryState.
//
// Алгоритм работы:
//  1. Формирует иерархический ключ для поиска данных репозитория
//  2. Выполняет запрос к datastore для получения сырых данных
//  3. Обрабатывает случай отсутствия данных (новый репозиторий)
//  4. Десериализует JSON в структуру RepositoryState
//  5. Возвращает готовое состояние или ошибку
//
// Параметры:
//
//	ctx - контекст для отмены операции и timeout'ов
//	repoID - уникальный идентификатор репозитория
//
// Возвращает:
//
//	RepositoryState - десериализованное состояние репозитория
//	error - ошибку загрузки или десериализации
//
// Обработка ошибок:
//   - ds.ErrNotFound: возвращает состояние по умолчанию для нового репозитория
//   - JSON unmarshal errors: возвращает ошибку с контекстом
//   - Datastore errors: оборачивает и возвращает с дополнительным контекстом
//
// Потокобезопасность:
//   - Метод полностью потокобезопасен
//   - Не модифицирует внутреннее состояние объекта
//   - Может выполняться concurrent с другими операциями
func (h *datastoreHeadStorage) LoadHead(ctx context.Context, repoID string) (RepositoryState, error) {
	// Формируем иерархический ключ: /repository/{repoID}/head
	// Такая структура позволяет легко масштабировать и организовывать данные
	key := ds.NewKey("repository").ChildString(repoID).ChildString("head")

	// Выполняем запрос к datastore с учетом контекста
	data, err := h.ds.Get(ctx, key)
	if err != nil {
		// Специальная обработка случая отсутствия данных
		// Для нового репозитория это нормальная ситуация, не ошибка
		if err == ds.ErrNotFound {
			// Возвращаем состояние по умолчанию для неинициализированного репозитория
			return RepositoryState{
				Head:    cid.Undef, // Undefined CID указывает на отсутствие коммитов
				Prev:    cid.Undef, // Нет предыдущего коммита
				Version: 1,         // Текущая версия формата
				RepoID:  repoID,    // Сохраняем переданный идентификатор
			}, nil
		}
		// Для всех остальных ошибок datastore оборачиваем с контекстом
		return RepositoryState{}, fmt.Errorf("failed to load head state: %w", err)
	}

	// Десериализуем JSON данные в структуру
	var state RepositoryState
	if err := json.Unmarshal(data, &state); err != nil {
		// Ошибки десериализации могут указывать на corruption данных
		// или несовместимость версий формата
		return RepositoryState{}, fmt.Errorf("failed to unmarshal head state: %w", err)
	}

	return state, nil
}

// SaveHead сохраняет текущее состояние репозитория в datastore и уведомляет watchers.
// Метод обеспечивает атомарность операции и автоматическое уведомление подписчиков.
//
// Алгоритм работы:
//  1. Сериализует состояние в JSON формат
//  2. Формирует ключ для хранения в datastore
//  3. Атомарно сохраняет данные в datastore
//  4. При успешном сохранении уведомляет всех активных watchers
//
// Параметры:
//
//	ctx - контекст для отмены операции и timeout'ов
//	repoID - уникальный идентификатор репозитория
//	state - новое состояние репозитория для сохранения
//
// Возвращает:
//
//	error - ошибку сериализации или сохранения
//
// Гарантии:
//   - Операция атомарна: либо полностью успешна, либо не выполняется
//   - При ошибке сохранения watchers не уведомляются
//   - JSON сериализация выполняется с компактным форматом
//   - Уведомления watchers происходят только после успешного сохранения
//
// Потокобезопасность:
//   - Полностью потокобезопасен для concurrent вызовов
//   - Уведомления watchers защищены от race conditions
//   - Не блокируется на медленных watchers благодаря non-blocking отправке
//
// Обработка ошибок:
//   - JSON marshal errors: проблемы с сериализацией структуры
//   - Datastore errors: проблемы с underlying storage
//   - Все ошибки оборачиваются с контекстом для лучшей диагностики
func (h *datastoreHeadStorage) SaveHead(ctx context.Context, repoID string, state RepositoryState) error {
	// Формируем тот же иерархический ключ, что и при загрузке
	key := ds.NewKey("repository").ChildString(repoID).ChildString("head")

	// Сериализуем состояние в компактный JSON
	// Используем стандартную сериализацию без отступов для экономии места
	data, err := json.Marshal(state)
	if err != nil {
		// Ошибки сериализации обычно указывают на проблемы со структурой данных
		return fmt.Errorf("failed to marshal head state: %w", err)
	}

	// Атомарно сохраняем данные в datastore
	// Datastore должен гарантировать atomicity этой операции
	if err := h.ds.Put(ctx, key, data); err != nil {
		// Оборачиваем ошибку datastore с контекстом для лучшей диагностики
		return fmt.Errorf("failed to save head state: %w", err)
	}

	// Уведомляем всех подписчиков об изменении состояния
	// Это происходит только после успешного сохранения
	// Уведомления отправляются асинхронно и не блокируют операцию сохранения
	h.notifyWatchers(repoID, state)

	return nil
}

// WatchHead создает новую подписку на изменения состояния HEAD указанного репозитория.
// Возвращает буферизованный канал, через который будут приходить уведомления
// о каждом изменении состояния репозитория.
//
// Алгоритм работы:
//  1. Создает буферизованный канал для уведомлений
//  2. Добавляет канал в список активных watchers для репозитория
//  3. Запускает горутину для автоматической очистки при отмене контекста
//  4. Возвращает read-only канал клиенту
//
// Параметры:
//
//	ctx - контекст, при отмене которого подписка автоматически закрывается
//	repoID - уникальный идентификатор репозитория для отслеживания
//
// Возвращает:
//
//	<-chan RepositoryState - read-only канал для получения уведомлений
//	error - ошибку создания подписки (в текущей реализации всегда nil)
//
// Особенности буферизации:
//   - Канал буферизован на 10 элементов для предотвращения блокировки
//   - При переполнении буфера новые уведомления пропускаются (non-blocking)
//   - Это защищает систему от медленных или зависших consumer'ов
//
// Управление жизненным циклом:
//   - При отмене контекста канал автоматически закрывается
//   - Watcher автоматически удаляется из внутреннего реестра
//   - Горутина автоматически завершается при закрытии канала
//   - Нет необходимости в ручной очистке ресурсов
//
// Потокобезопасность:
//   - Полностью потокобезопасен для concurrent подписок
//   - Защищен мьютексом от race conditions при добавлении watchers
//   - Безопасен для использования из множественных горутин
//
// Примечания по производительности:
//   - Подписка создается мгновенно без I/O операций
//   - Не отправляет текущее состояние при создании подписки
//   - Уведомления отправляются только при изменениях через SaveHead
func (h *datastoreHeadStorage) WatchHead(ctx context.Context, repoID string) (<-chan RepositoryState, error) {
	// Создаем буферизованный канал для предотвращения блокировки при медленных consumer'ах
	// Размер буфера 10 - компромисс между памятью и защитой от кратковременных задержек
	ch := make(chan RepositoryState, 10)

	// Безопасно добавляем новый watcher в реестр
	h.mu.Lock()
	h.watchers[repoID] = append(h.watchers[repoID], ch)
	h.mu.Unlock()

	// Запускаем горутину для автоматической очистки при отмене контекста
	// Это обеспечивает правильное управление ресурсами без участия клиента
	go func() {
		// Ожидаем отмены контекста
		<-ctx.Done()

		// Удаляем watcher из реестра для предотвращения утечек памяти
		h.removeWatcher(repoID, ch)

		// Закрываем канал для уведомления consumer'а о завершении подписки
		close(ch)
	}()

	// Возвращаем read-only канал клиенту
	return ch, nil
}

// Close выполняет корректное закрытие datastoreHeadStorage и освобождение всех ресурсов.
// Метод обеспечивает graceful shutdown всех активных подписок и очистку внутреннего состояния.
//
// Алгоритм работы:
//  1. Блокирует доступ к watchers для предотвращения новых подписок
//  2. Итерирует по всем активным watchers для всех репозиториев
//  3. Закрывает каждый канал для уведомления consumer'ов о завершении
//  4. Очищает внутреннюю карту watchers для предотвращения утечек памяти
//  5. Освобождает блокировку
//
// Возвращает:
//
//	error - ошибку закрытия (в текущей реализации всегда nil)
//
// Поведение после закрытия:
//   - Все активные подписки (WatchHead) получат закрытые каналы
//   - Новые вызовы WatchHead могут создавать watchers, но это не рекомендуется
//   - SaveHead и LoadHead остаются функциональными (зависят от datastore)
//   - Повторный вызов Close безопасен (idempotent)
//
// Потокобезопасность:
//   - Использует exclusive lock для полной синхронизации
//   - Предотвращает race conditions при concurrent закрытии
//   - Гарантирует, что все watchers будут корректно закрыты
//
// Управление ресурсами:
//   - Не закрывает underlying datastore (не является владельцем)
//   - Закрывает только каналы, созданные этим storage
//   - Очищает всю внутреннюю память, связанную с watchers
//
// Примечания:
//   - Метод блокирующий и может занять время при большом количестве watchers
//   - Рекомендуется вызывать в defer или explicit cleanup
//   - После вызова объект может быть повторно использован, но это не рекомендуется
func (h *datastoreHeadStorage) Close() error {
	// Получаем exclusive lock для предотвращения concurrent доступа
	// во время закрытия ресурсов
	h.mu.Lock()
	defer h.mu.Unlock()

	// Итерируем по всем репозиториям и их watchers
	for _, watchers := range h.watchers {
		// Закрываем каждый канал для уведомления consumer'ов
		for _, ch := range watchers {
			// close() безопасен для уже закрытых каналов,
			// но мы не проверяем это для упрощения кода
			close(ch)
		}
	}

	// Создаем новую пустую карту для очистки ссылок на старые каналы
	// Это важно для предотвращения утечек памяти
	h.watchers = make(map[string][]chan RepositoryState)

	// В текущей реализации всегда возвращаем nil
	// В будущем здесь может быть логика закрытия дополнительных ресурсов
	return nil
}

// notifyWatchers отправляет уведомления о изменении состояния всем активным подписчикам.
// Метод реализует non-blocking уведомления для предотвращения deadlocks и зависаний.
//
// Алгоритм работы:
//  1. Получает read lock для безопасного доступа к списку watchers
//  2. Создает локальную копию списка watchers для указанного репозитория
//  3. Освобождает lock для минимизации времени блокировки
//  4. Итерирует по всем watchers и пытается отправить уведомление
//  5. Использует select с default для non-blocking отправки
//
// Параметры:
//
//	repoID - идентификатор репозитория, watchers которого нужно уведомить
//	state - новое состояние репозитория для отправки
//
// Non-blocking гарантии:
//   - Если канал watcher'а заполнен, уведомление пропускается
//   - Это предотвращает блокировку операций SaveHead на медленных consumer'ах
//   - Медленные или зависшие watchers не влияют на производительность системы
//
// Потокобезопасность:
//   - Использует RWMutex для concurrent доступа к watchers
//   - Read lock позволяет множественным уведомлениям выполняться параллельно
//   - Минимизирует время блокировки для лучшей производительности
//
// Обработка закрытых каналов:
//   - Отправка в закрытый канал вызовет panic
//   - В текущей реализации предполагается, что каналы управляются корректно
//   - Close() должен вызываться перед удалением watchers
//
// Примечания по производительности:
//   - Быстрое выполнение благодаря non-blocking отправке
//   - Не выполняет I/O операций или тяжелых вычислений
//   - Минимальное время удержания locks для лучшего concurrency
func (h *datastoreHeadStorage) notifyWatchers(repoID string, state RepositoryState) {
	// Получаем read lock для безопасного доступа к watchers map
	// RLock позволяет concurrent выполнение множественных уведомлений
	h.mu.RLock()
	// Создаем локальную копию слайса watchers для минимизации времени lock'а
	watchers := h.watchers[repoID]
	h.mu.RUnlock()

	// Итерируем по всем watchers для данного репозитория
	for _, ch := range watchers {
		// Используем select с default для non-blocking отправки
		select {
		case ch <- state:
			// Уведомление успешно отправлено в канал
			// Consumer получит новое состояние репозитория
		default:
			// Канал заполнен или watcher медленный - пропускаем уведомление
			// Это предотвращает блокировку всей системы из-за одного медленного consumer'а
			// В production может быть полезно логировать такие случаи для мониторинга
		}
	}
}

// removeWatcher безопасно удаляет указанный watcher из списка активных подписчиков.
// Метод используется для очистки ресурсов при отмене контекста или закрытии подписки.
//
// Алгоритм работы:
//  1. Получает exclusive lock для безопасной модификации watchers map
//  2. Находит указанный канал в списке watchers для репозитория
//  3. Удаляет найденный канал из слайса, сохраняя порядок остальных
//  4. Обновляет watchers map с новым слайсом
//  5. Освобождает lock
//
// Параметры:
//
//	repoID - идентификатор репозитория, из watchers которого удаляется подписчик
//	target - конкретный канал, который нужно удалить из списка
//
// Поиск и удаление:
//   - Использует линейный поиск по адресу канала (pointer comparison)
//   - Удаляет только первое найденное совпадение
//   - Если канал не найден, операция завершается без изменений
//   - Использует эффективное slice manipulation для удаления элемента
//
// Потокобезопасность:
//   - Использует exclusive lock для предотвращения race conditions
//   - Безопасен для concurrent вызовов из разных горутин
//   - Синхронизирован с notifyWatchers и WatchHead методами
//
// Управление памятью:
//   - Правильное удаление предотвращает утечки памяти
//   - Не закрывает канал (это ответственность вызывающего кода)
//   - Уменьшает slice capacity при необходимости
//
// Производительность:
//   - O(n) сложность по количеству watchers для репозитория
//   - Быстрое выполнение благодаря простой логике поиска
//   - Минимальное время удержания lock'а
//
// Примечания:
//   - Метод не проверяет, закрыт ли канал
//   - Предполагается, что target канал существует в списке
//   - Если канал отсутствует, операция молча завершается
func (h *datastoreHeadStorage) removeWatcher(repoID string, target chan RepositoryState) {
	// Получаем exclusive lock для безопасной модификации watchers map
	h.mu.Lock()
	defer h.mu.Unlock()

	// Получаем текущий список watchers для репозитория
	watchers := h.watchers[repoID]

	// Выполняем линейный поиск целевого канала
	for i, ch := range watchers {
		// Сравниваем по адресу канала (pointer comparison)
		if ch == target {
			// Удаляем элемент из слайса, сохраняя порядок
			// Используем стандартный Go паттерн для удаления элемента из slice
			h.watchers[repoID] = append(watchers[:i], watchers[i+1:]...)

			// Прерываем поиск после первого найденного совпадения
			// Это предотвращает удаление дубликатов, если они есть
			break
		}
	}
}
